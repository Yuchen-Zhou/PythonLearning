{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Beautiful Soup\n",
    "    对于一个网页来说，有一定的特殊结构和层级关系，而且很多节点都有id或class来作区分，所以借助它们的结构和属性提取会更加便捷  \n",
    "    这节，就来介绍一个强大的解析工具Beautiful Soup，它借助网页的结构和属性等特征来解析网页。有了它，就不用再去写一些复杂的正则表达式，只需要简单的几条语句，就可以完成网页中某个元素的提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、简介\n",
    "    简单来说，Beautiful Soup就是Python的一个HTML或XML的解析库，可以用它来方便地从网页中提取数据。官方解释如下：  \n",
    "        ·Beautiful Soup提供一些简单的、Python式的函数来处理导航、搜索、修改分析树等功能。它是一个工具箱没通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序\n",
    "        ·Beautiful Soup自动将输入的文档转换成Unicode编码，输出文档转换为UTF-8编码。你不需要考虑编码格式，除非文档没有指定一个编码方式，这是你仅仅需要说明一下原始编码方式就可以来  \n",
    "        ·Beautiful Soup已成为和lxml、html6lib一样的出色的Python解释器，为用户灵活地提供不同的解析策略或强劲的速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、准备工作\n",
    "    在开始之前，请确保已经安装好Beautiful Soup和lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、解析器\n",
    "    Beautiful Soup在解析时实际上非常依赖解析器，它除了支持Python标准库中的HTML解析器外，还支持一些第三方解析器（比如lxml）\n",
    "    \n",
    "                            Beautiful Soup支持的解析器  \n",
    "|解析器|使用方法|优势|劣势|  \n",
    "|----|---|---|---|\n",
    "|Python标准库|BeautifulSoup(markup, 'html.parser')|Python的内置标准库、执行速度适中、文档容错能力强|Python2.7.3及Python3.2.2之前的版本文档容错能力差|\n",
    "|lxml HTML解析器|BeautifulSoup(markup, 'lxml')|速度快、文档容错能力强|需要安装C语言库|\n",
    "|lxml XML解析器|BeautifulSoup(markup, 'xml'|速度快、唯一支持XML的解析器|需要安装C语言库|\n",
    "|html5lib|BeautifulSoup(markup, 'html5lib')|最好的容错性、以浏览器的方式解析文档、生成HTML5格式的文档|速度慢、不依赖外部扩展|\n",
    "\n",
    "通过以上对比可以看出，lxml解析器有解析HTML和XML的功能，而且速度快，容错能力强，所以推荐使用它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "#如果使用lxml，那么在初始化Beautiful Soup时，可以把第二个参数改为lxml即可\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup('<p>Hello</p>', 'lxml')\n",
    "print(soup.p.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、基本用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\" name=\"dormouse\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><!-- Elsie --></a>, \n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tittle\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "# print(soup.prettify())\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是首先声明变量html，它是一个HTML字符串。但是需要注意的是，它并不是一个完整的HTML字符串，因为body和html节点都没有闭合。接着，我们将它当作第一个参数传给BeautifulSoup对象，该对象的第二个参数作为解析器的类型（这里使用lxml），此时就完成了BeautifulSoup对象的初始化。然后，将这个对象赋值给soup变量\n",
    "\n",
    "接下来，就可以调用soup的各个方法和属性解析这串HTML代码了\n",
    "\n",
    "首先，调用prettify()方法。这个方法可以把要解析的字符串以标准的缩进格式输出。这里需要注意的是，输出结果里面包含body和html节点，也就是说对于不标准的HTML字符串BeautifulSoup可以自动更正格式。这不是由prettify()方法做的，而是在初始化BeautifulSoup时就完成了\n",
    "\n",
    "然后调用soup.title.string,这实际上是输出HTML中title节点的文本内容。所以，soup.title可以选出HTML中的title节点，再调用string属性就可以得到里面的文本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、节点选择器\n",
    "    直接调用节点的名称就可以选择节点元素，再调用string属性就可以得到节点内的文本了，这种选择方式速度非常快。如果单个节点结构层次非常清晰，可以选用这种方式来解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·选择元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "The Dormouse's story\n",
      "<head><title>The Dormouse's story</title></head>\n",
      "<p class=\"title\" name=\"dormouse\"><b>The Dormouse's story</b></p>\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\" name=\"dormouse\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><!-- Elsie --></a>, \n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tittle\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.title)\n",
    "print(type(soup.title))\n",
    "print(soup.title.string)\n",
    "print(soup.head)\n",
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里依然选用刚才的HTML代码，首先打印输出title节点的选择结果，输出结果正是title节点加里面的文字内容。接下来，输出它的类型，是bs.element.Tag类型，这是Beautiful Soup中一个重要的数据结构。经过选择器选择后，选择结果都是这种Tag类型。Tag具有一些属性，比如string属性，调用该属性，可以得到节点的文本内容，所以接下来的输出结果正是节点的文本内容。\n",
    "\n",
    "接下来，我们又尝试选择了head节点，结果也是节点加其内部的所有内容。最后，选择了p节点。不过这次情况比较特殊，我们发现结果是第一个p节点的内容，后面的几个p节点并没有选到。也就是说，当有多个节点时，这种选择方式只会选择到第一个匹配的节点，其他的后面节点都会忽略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·提取信息\n",
    "    上面演示了调用string属性来获取文本的值，下面是信息的提取方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）获取名称\n",
    "            可以利用name属性获取节点的名称。这里还是以上面的文本为例，选取title节点，然后调用name属性就可以得到节点名称："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）获取属性\n",
    "            每个节点可能有多个属性，比如id和class等，选择这个节点元素后，可以调用attrs获取所有属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dormouse\n",
      "['title']\n"
     ]
    }
   ],
   "source": [
    "print(soup.p['name'])\n",
    "print(soup.p['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里需要注意的是，有的返回结果是字符串，有的返回结果是字符串组成的列表。比如，name属性的值是唯一的，返回的结果就是单个字符串。而对于class，一个节点元素可能有多个class，所以返回的列表。在实际处理过程中，我们需要注意判断类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）获取内容\n",
    "            可以利用string属性获取节点元素包含的文本内容，比如要获取第一个p节点的文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "print(soup.p.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·嵌套选择\n",
    "    在上面例子中，我们知道每一个返回结果都是bs4.element.Tag类型，它同样可以继续调用节点进行下一步的选择。比如，我们获取了head节点元素，我们可以继续调用head来选取内部的head节点元素："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.head.title)\n",
    "print(type(soup.head.title))\n",
    "print(soup.head.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一行结果是调用head之后再次调用title而选择的title节点元素。然后打印输出了它的类型，可以看到，它仍是bs4.element.Tag类型。也就是说，我们在Tag类型的基础上再次选择得到了依然还是Tag类型，每次返回的结果都相同，所以这样就可以做嵌套选择了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·关联选择\n",
    "    在做选择的时候，有时候不能做到一步就选到想要的节点元素，需要先选中某一个节点元素，然后以它为基准再选择它的子节点、父节点、兄弟节点等，这里就来介绍如何选择这些节点元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）子节点和子孙节点\n",
    "            选取节点元素之后，如果想要获取它的直接子节点，可以调用contents属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n    Once upon a time there were little sisters; and their names were\\n    ', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>English</span>\n",
      "</a>, '\\n', <a href=\"http://example.com/tillie class=\" id=\"link2\" sister=\"\">Lacie</a>, '\\nand they lived at the bottom of well\\n']\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>The Dormouse's story</title>\n",
    "</head>\n",
    "<body>\n",
    "<p class=\"story\">\n",
    "    Once upon a time there were little sisters; and their names were\n",
    "    <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "<span>English</span>\n",
    "</a>\n",
    "<a href=\"http://example.com/tillie class=\"sister\" id=\"link2\">Lacie</a>\n",
    "and they lived at the bottom of well\n",
    "</p>\n",
    "<p class='story'>...</p>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.p.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，返回结果是列表形式。p节点里既包含文本，又包含节点，最后会将它们以列表形式统一返回  \n",
    "需要注意的是，列表中的每个元素都是p节点的直接子节点。比如第一个a节点里面包含一层span节点，这相当于子孙节点了，但是返回结果并没有单独把span节点选出来。所以说，content属性得到的结果是直接子节点的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<list_iterator object at 0x7fce61494cd0>\n",
      "0 \n",
      "    Once upon a time there were little sisters; and their names were\n",
      "    \n",
      "1 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>English</span>\n",
      "</a>\n",
      "2 \n",
      "\n",
      "3 <a href=\"http://example.com/tillie class=\" id=\"link2\" sister=\"\">Lacie</a>\n",
      "4 \n",
      "and they lived at the bottom of well\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#同样，可以调用children属性得到相应的结果\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.p.children)\n",
    "for i, child in enumerate(soup.p.children):\n",
    "    print(i, child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是同样的HTML文本，这里调用了children属性来选择，返回结果是生成器类型。接下来，我们用for循环输出相应的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Tag.descendants at 0x7fce61497740>\n",
      "0 \n",
      "    Once upon a time there were little sisters; and their names were\n",
      "    \n",
      "1 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>English</span>\n",
      "</a>\n",
      "2 \n",
      "\n",
      "3 <span>English</span>\n",
      "4 English\n",
      "5 \n",
      "\n",
      "6 \n",
      "\n",
      "7 <a href=\"http://example.com/tillie class=\" id=\"link2\" sister=\"\">Lacie</a>\n",
      "8 Lacie\n",
      "9 \n",
      "and they lived at the bottom of well\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#如果要得到所有的子孙节点的话，可以调用descendants属性\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.p.descendants)\n",
    "for i, child in enumerate(soup.p.descendants):\n",
    "    print(i, child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时返回结果还是生成器。遍历输出一下可以看到，这次输出的结果就包含了span节点。descendants会递归查询所有子节点，得到所有的子节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）父节点和祖先节点\n",
    "            如果想要获取某个节点元素的父节点，可以调用paren属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"story\">\n",
      "    Once upon a time there were little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>English</span>\n",
      "</a>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>The Dormouse's story</title>\n",
    "</head>\n",
    "<body>\n",
    "<p class=\"story\">\n",
    "    Once upon a time there were little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "<span>English</span>\n",
    "</a>\n",
    "</p>\n",
    "<p class='story'>...</p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.a.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们选择的是第一个a节点的父节点元素。很明显，它的父节点是p节点，输出结果便是p节点及其内部的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "[(0, <p class=\"story\">\n",
      "    Once upon a time there were little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>English</span>\n",
      "</a>\n",
      "</p>), (1, <body>\n",
      "<p class=\"story\">\n",
      "    Once upon a time there were little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>English</span>\n",
      "</a>\n",
      "</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body>), (2, <html>\n",
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "<body>\n",
      "<p class=\"story\">\n",
      "    Once upon a time there were little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>English</span>\n",
      "</a>\n",
      "</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body></html>), (3, <html>\n",
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "<body>\n",
      "<p class=\"story\">\n",
      "    Once upon a time there were little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "<span>English</span>\n",
      "</a>\n",
      "</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body></html>)]\n"
     ]
    }
   ],
   "source": [
    "#如果想要获取所有的祖先节点，可以调用parents属性\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>The Dormouse's story</title>\n",
    "</head>\n",
    "<body>\n",
    "<p class=\"story\">\n",
    "    Once upon a time there were little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "<span>English</span>\n",
    "</a>\n",
    "</p>\n",
    "<p class='story'>...</p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(type(soup.a.parents))\n",
    "print(list(enumerate(soup.a.parents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，返回结果是生成器类型。这里用列表输出了它的索引和内容，而列表中的元素就是a节点的祖先节点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）兄弟节点\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Sibling \n",
      "            Hello\n",
      "\n",
      "Prev Sibling \n",
      "            Once upon a time there were three little sisters; and their name were\n",
      "\n",
      "Next Siblings [(0, '\\n            Hello\\n'), (1, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>), (2, '\\n            and\\n'), (3, <a class=\"sister\" href=\"http://example.com/title\" id=\"link3\">Tittle</a>), (4, '\\n            and they lived at the bottom of well.\\n')]\n",
      "Prev Siblings [(0, '\\n            Once upon a time there were three little sisters; and their name were\\n')]\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<p class=\"story\">\n",
    "            Once upon a time there were three little sisters; and their name were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">\n",
    "<span>Elsie</span>\n",
    "</a>\n",
    "            Hello\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "            and\n",
    "<a href=\"http://example.com/title\" class=\"sister\" id=\"link3\">Tittle</a>\n",
    "            and they lived at the bottom of well.\n",
    "</p>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print('Next Sibling', soup.a.next_sibling)\n",
    "print('Prev Sibling', soup.a.previous_sibling)\n",
    "print('Next Siblings', list(enumerate(soup.a.next_siblings)))\n",
    "print('Prev Siblings', list(enumerate(soup.a.previous_siblings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里调用了4个属性，其中next_sibling和previous_sibling分别获取节点的下一个和上一个兄弟元素，next_siblings和previous_siblings则分别返回所有前面和后面的兄弟节点的生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （4）提取信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Once upon a time there were three little sisters;and their name were\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "#前面讲了关联元素节点的选择方法，如果想要获取它们的一些信息，比如文本、属性等，方法如下：\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<p class=\"story\">\n",
    "            Once upon a time there were three little sisters;and their name were\n",
    "            <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Bob</a>\n",
    "            <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "</p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "# print('Next Sibling:')\n",
    "# print(type(soup.a.next_sibling))\n",
    "# print(soup.a.next_sibling)\n",
    "# print(soup.a.next_sibling.string)\n",
    "# print('Parent:')\n",
    "# print(type(soup.a.parents))\n",
    "print(list(soup.a.parent)[0])\n",
    "# print(list(soup.a.parents)[0].attrs['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果返回结果是单个节点，那么可以直接调用string、attrs等属性获得其文本和属性；如果返回结果是多个节点的生成器，则可以转化为列表后取出某个元素，然后再调用string、attrs等属性获取其对应节点的文本和属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、方法选择器\n",
    "    前面所讲的选择方法都是通过属性来选择的，这种方法非常快，但是如果进行比较复杂的选择的时候，它就比较麻烦。Beautiful Soup还提供来一些查询方法，比如，find_all()和find()等，调用它们，然后传入相应的参数，就可以灵活查询来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·find_all()\n",
    "        顾名思义，就是查询所有符合条件的元素。给它传入一些属性或文本，就可以得到符合条件的元素，它的功能十分强大，API：  \n",
    "         find_all(name, attrs, recursive, text, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>, <ul class=\"list list-small\" id=\"list-2\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "</ul>]\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "#我们可以根据节点名来查询元素\n",
    "html = \"\"\"\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-heading\">\n",
    "<h4>Hello</h4>\n",
    "</div>\n",
    "<div class=\"panel-body\">\n",
    "<ul class=\"list\" id=\"list-1\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "<li class=\"element\">Jay</li>\n",
    "</ul>\n",
    "<ul class=\"list list-small\" id=\"list-2\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(name='ul'))\n",
    "print(type(soup.find_all(name='ul')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里调用find_all()方法，传入name参数，其参数值为ul。也就是说，我们想要查询所有ul节点，返回结果是列表类型，长度为2，每个元素依然都是bs4.element.Tag类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n"
     ]
    }
   ],
   "source": [
    "#因为都是Tag类型，所以依然可以进行嵌套查询。还是同样的文本，这里查询所有ul节点后，再继续查询其内部的li节点\n",
    "for ul in soup.find_all(name='ul'):\n",
    "    print(ul.find_all(name='li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回结果是列表类型，列表中的每个元素依然还是Tag类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "Foo\n",
      "Bar\n",
      "Jay\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "Foo\n",
      "Bar\n"
     ]
    }
   ],
   "source": [
    "#接下来，遍历每个li，获取它的文本\n",
    "for ul in soup.find_all(name='ul'):\n",
    "    print(ul.find_all(name='li'))\n",
    "    for li in ul.find_all(name='li'):\n",
    "        print(li.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n",
      "[<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n"
     ]
    }
   ],
   "source": [
    "#我们可以根据节点名来查询元素\n",
    "html = \"\"\"\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-heading\">\n",
    "<h4>Hello</h4>\n",
    "</div>\n",
    "<div class=\"panel-body\">\n",
    "<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "<li class=\"element\">Jay</li>\n",
    "</ul>\n",
    "<ul class=\"list list-small\" id=\"list-2\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(attrs={'id': 'list-1'}))\n",
    "print(soup.find_all(attrs={'name': 'elements'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里查询的时候传入的是attrs参数，参数的类型是字典类型。比如，要查询id为list-1的节点，可以传入attrs={'id':'list-1'}的查询条件，得到的结果是列表形式，包含的内容就是符合id为list-1的所有节点。在上面的例子中，符合条件的元素个数是1，所以结果是长度为1的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>, <li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n"
     ]
    }
   ],
   "source": [
    "#对于一些常用属性，比如id和class等，我们可以不用attrs来传递。比如，要查询id为list-1的节点，可以直接传入id参数\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(id='list-1'))\n",
    "print(soup.find_all(class_='element'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里直接传入id='list-1'，就可以查询id为list-1的节点元素。而对于class来说，由于clas在Python里是一个关键字，所以后面需要加一个下划线，即class_='element'，返回的结果依然还是Tag组成的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, this is a link', 'Hello, this is a link, too']\n"
     ]
    }
   ],
   "source": [
    "#text参数可用来匹配节点的文本，传入的形式可以是字符串，可以是正则表达式\n",
    "import re\n",
    "html = \"\"\"\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-body\">\n",
    "<a>Hello, this is a link</a>\n",
    "<a>Hello, this is a link, too</a>\n",
    "</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find_all(text=re.compile('link')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有两个a节点，其内部包含文本信息。这里在find_all()方法传入text参数，该参数为正则表达式对象，结果返回所有匹配正则表达式的节点文本组成的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·find()\n",
    "   除了find_all()方法，还有find()方法，只不过后者返回的是单个元素，也就是第一个匹配的元素，而前者返回的是所有匹配的元素组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>\n",
      "<class 'bs4.element.Tag'>\n",
      "<ul class=\"list\" id=\"list-1\">\n",
      "<li class=\"element\">Foo</li>\n",
      "<li class=\"element\">Bar</li>\n",
      "<li class=\"element\">Jay</li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-heading\">\n",
    "<h4>Hello</h4>\n",
    "</div>\n",
    "<div class=\"panel-body\">\n",
    "<ul class=\"list\" id=\"list-1\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "<li class=\"element\">Jay</li>\n",
    "</ul>\n",
    "<ul class=\"list list-small\" id=\"list-2\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.find(name='ul'))\n",
    "print(type(soup.find(name='ul')))\n",
    "print(soup.find(class_='list'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里返回的结果不再是列表形式，而是第一个匹配的节点元素，类型依然是Tag类型  \n",
    "另外，还有许多查询方法，其用法与前面介绍的find_all()、find()方法完全相同，只不过查询范围不同，这里简单说明 \n",
    "       \n",
    "       ·find_parents()和find_parent()：前者返回所有祖先节点，后者返回直接父节点  \n",
    "       ·find_next_siblings()和find_next_sibling()：前者返回后面所有的兄弟节点，后者返回后面的第一个兄弟节点  \n",
    "       ·find_previous_siblings()和find_previous_sibling()；前者返回前面所有的兄弟节点，后者返回前面第一个兄弟节点  \n",
    "       ·find_all_next()和find_next()：前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点  \n",
    "       ·find_all_previous()和find_previous()：前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七、CSS选择器\n",
    "    Beautiful Soup还提供了另外一种选择器，CSS选择器。如果对Web开发熟悉的话，那么对CSS选择器肯定也不陌生。如果不熟悉的话，参考http://www.w3school.com.cn/cssref/css_selectors.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"panel-heading\">\n",
      "<h4>Hello</h4>\n",
      "</div>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>, <li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "#使用CSS选择器时，只需要调用select()方法，传入相应的CSS选择器\n",
    "html = \"\"\"\n",
    "<div class=\"panel\">\n",
    "<div class=\"panel-heading\">\n",
    "<h4>Hello</h4>\n",
    "</div>\n",
    "<div class=\"panel-body\">\n",
    "<ul class=\"list\" id=\"list-1\" name=\"elements\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "<li class=\"element\">Jay</li>\n",
    "</ul>\n",
    "<ul class=\"list list-small\" id=\"list-2\">\n",
    "<li class=\"element\">Foo</li>\n",
    "<li class=\"element\">Bar</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup.select('.panel .panel-heading'))\n",
    "print(soup.select('ul li'))\n",
    "print(soup.select('#list-2 .element'))\n",
    "print(type(soup.select('ul')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们用了3次CSS选择器，返回的结果均是符合CSS选择器的节点组成的列表。例如，select('ul li')则是选择所有ul节点下面的所有li节点，结果便是所有的li节点组成的列表  \n",
    "最后打印输出列表中元素的类型，依然是Tag类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·嵌套选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>, <li class=\"element\">Jay</li>]\n",
      "[<li class=\"element\">Foo</li>, <li class=\"element\">Bar</li>]\n"
     ]
    }
   ],
   "source": [
    "#select()方法同样支持嵌套选择。例如，先选择所有的ul节点，再遍历每个ul节点，选择其li节点\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for ul in soup.select('ul'):\n",
    "    print(ul.select('li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·获取属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list-1\n",
      "list-1\n",
      "list-2\n",
      "list-2\n"
     ]
    }
   ],
   "source": [
    "#节点类型是Tag类型，所以获取属性还可以用原来的方法。\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for ul in soup.select('ul'):\n",
    "    print(ul['id'])\n",
    "    print(ul.attrs['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，直接传入中括号和属性名，以及通过attrs属性获取属性值，都可以成功"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ·获取文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Text: Foo\n",
      "String: Foo\n",
      "Get Text: Bar\n",
      "String: Bar\n",
      "Get Text: Jay\n",
      "String: Jay\n",
      "Get Text: Foo\n",
      "String: Foo\n",
      "Get Text: Bar\n",
      "String: Bar\n"
     ]
    }
   ],
   "source": [
    "#要获取文本，可以用之前的string属性，也可以用get_text()\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for li in soup.select('li'):\n",
    "    print('Get Text:', li.get_text())\n",
    "    print('String:', li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup总结：\n",
    "        ·推荐使用lxml解析库，必要时使用html.parser\n",
    "        ·节点选择筛选功能弱但是速度快\n",
    "        ·建议使用find()或者find_all()查询匹配单个结果或者多个结果\n",
    "        ·如果对CSS选择器熟悉的话，可以使用select()方法选择"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.4px",
    "left": "769px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
